{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrGv2RHQPmdI",
        "outputId": "5a0e31d6-ef92-4f85-9f9f-7e9c5aa564f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/afnan47/cuda.git\n",
            "  Cloning https://github.com/afnan47/cuda.git to /tmp/pip-req-build-z127mi4b\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/afnan47/cuda.git /tmp/pip-req-build-z127mi4b\n",
            "  Resolved https://github.com/afnan47/cuda.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4287 sha256=67d9857ceb35c08d9229c7607dfbbb4c6a9c081e8faa1bc1a59c83a43e304fae\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vz9urlxt/wheels/aa/f3/44/e10c1d226ec561d971fcd4b0463f6bff08602afa928a3e7bc7\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/afnan47/cuda.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZKcBv0PQImN",
        "outputId": "db1f3ef3-9900-4fba-f5d7-2c104bfae660"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ],
      "source": [
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXtkUCowQZqd",
        "outputId": "d248be7c-63b9-4cc3-cd59-3a5962cea92a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Minimum value: 1\n",
            "Maximum value: 256\n",
            "Sum: 32896\n",
            "Average: 128.50\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cu\n",
        "// WARNING: DO NOT COPY THIS CODE, INSTEAD DOWNLOAD IT TO AVOID ERRORS.\n",
        "#include <stdio.h>\n",
        "\n",
        "#define BLOCK_SIZE 256\n",
        "\n",
        "// Kernel for parallel reduction using min operation\n",
        "__global__ void reduceMin(int* input, int* output, int size) {\n",
        "    __shared__ int sdata[BLOCK_SIZE];\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Load data into shared memory\n",
        "    if (i < size) {\n",
        "        sdata[tid] = input[i];\n",
        "    } else {\n",
        "        sdata[tid] = INT_MAX;\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // Perform reduction within each block\n",
        "    for (unsigned int stride = blockDim.x / 2; stride > 0; stride >>= 1) {\n",
        "        if (tid < stride) {\n",
        "            sdata[tid] = min(sdata[tid], sdata[tid + stride]);\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Write the result for this block to global memory\n",
        "    if (tid == 0) {\n",
        "        output[blockIdx.x] = sdata[0];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Kernel for parallel reduction using max operation\n",
        "__global__ void reduceMax(int* input, int* output, int size) {\n",
        "    __shared__ int sdata[BLOCK_SIZE];\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Load data into shared memory\n",
        "    if (i < size) {\n",
        "        sdata[tid] = input[i];\n",
        "    } else {\n",
        "        sdata[tid] = INT_MIN;\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // Perform reduction within each block\n",
        "    for (unsigned int stride = blockDim.x / 2; stride > 0; stride >>= 1) {\n",
        "        if (tid < stride) {\n",
        "            sdata[tid] = max(sdata[tid], sdata[tid + stride]);\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Write the result for this block to global memory\n",
        "    if (tid == 0) {\n",
        "        output[blockIdx.x] = sdata[0];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Kernel for parallel reduction using sum operation\n",
        "__global__ void reduceSum(int* input, int* output, int size) {\n",
        "    __shared__ int sdata[BLOCK_SIZE];\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Load data into shared memory\n",
        "    if (i < size) {\n",
        "        sdata[tid] = input[i];\n",
        "    } else {\n",
        "        sdata[tid] = 0;\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // Perform reduction within each block\n",
        "    for (unsigned int stride = blockDim.x / 2; stride > 0; stride >>= 1) {\n",
        "        if (tid < stride) {\n",
        "            sdata[tid] += sdata[tid + stride];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Write the result for this block to global memory\n",
        "    if (tid == 0) {\n",
        "        output[blockIdx.x] = sdata[0];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Kernel for parallel reduction using average operation\n",
        "__global__ void reduceAverage(int* input, float* output, int size) {\n",
        "    __shared__ float sdata[BLOCK_SIZE];\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Load data into shared memory\n",
        "    if (i < size) {\n",
        "        sdata[tid] = static_cast<float>(input[i]);\n",
        "    } else {\n",
        "        sdata[tid] = 0.0f;\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // Perform reduction within each block\n",
        "    for (unsigned int stride = blockDim.x / 2; stride > 0; stride >>= 1) {\n",
        "        if (tid < stride) {\n",
        "            sdata[tid] += sdata[tid + stride];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Write the result for this block to global memory\n",
        "    if (tid == 0) {\n",
        "        output[blockIdx.x] = sdata[0] / static_cast<float>(size);\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Input array\n",
        "    const int array_size = 256;\n",
        "    int input[array_size];\n",
        "\n",
        "    // Initialize input array\n",
        "    for (int i = 0; i < array_size; ++i) {\n",
        "        input[i] = i + 1;\n",
        "    }\n",
        "\n",
        "    // Allocate device memory\n",
        "    int* d_input;\n",
        "    int* d_output_min;\n",
        "    int* d_output_max;\n",
        "    int* d_output_sum;\n",
        "    float* d_output_avg;\n",
        "    cudaMalloc((void**)&d_input, sizeof(int) * array_size);\n",
        "    cudaMalloc((void**)&d_output_min, sizeof(int) * array_size);\n",
        "    cudaMalloc((void**)&d_output_max, sizeof(int) * array_size);\n",
        "    cudaMalloc((void**)&d_output_sum, sizeof(int) * array_size);\n",
        "    cudaMalloc((void**)&d_output_avg, sizeof(float) * array_size);\n",
        "\n",
        "    // Copy input array to device memory\n",
        "    cudaMemcpy(d_input, input, sizeof(int) * array_size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Determine the number of threads and blocks\n",
        "    int threads_per_block = BLOCK_SIZE;\n",
        "    int blocks_per_grid = (array_size + threads_per_block - 1) / threads_per_block;\n",
        "\n",
        "    // Launch the kernels for parallel reduction\n",
        "    reduceMin<<<blocks_per_grid, threads_per_block>>>(d_input, d_output_min, array_size);\n",
        "    reduceMax<<<blocks_per_grid, threads_per_block>>>(d_input, d_output_max, array_size);\n",
        "    reduceSum<<<blocks_per_grid, threads_per_block>>>(d_input, d_output_sum, array_size);\n",
        "    reduceAverage<<<blocks_per_grid, threads_per_block>>>(d_input, d_output_avg, array_size);\n",
        "\n",
        "    // Copy the results back to the host\n",
        "    int min_result, max_result, sum_result;\n",
        "    float avg_result;\n",
        "    cudaMemcpy(&min_result, d_output_min, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    cudaMemcpy(&max_result, d_output_max, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    cudaMemcpy(&sum_result, d_output_sum, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    cudaMemcpy(&avg_result, d_output_avg, sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print the results\n",
        "    printf(\"Minimum value: %d\\n\", min_result);\n",
        "    printf(\"Maximum value: %d\\n\", max_result);\n",
        "    printf(\"Sum: %d\\n\", sum_result);\n",
        "    printf(\"Average: %.2f\\n\", avg_result);\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_output_min);\n",
        "    cudaFree(d_output_max);\n",
        "    cudaFree(d_output_sum);\n",
        "    cudaFree(d_output_avg);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
