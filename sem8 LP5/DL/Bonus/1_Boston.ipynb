{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "\n",
    "boston_dataset = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(boston_dataset.data,columns=boston_dataset.feature_names)\n",
    "df['MEDV'] = boston_dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90   5.33  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99   9.67  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      0\n",
       "CHAS       0\n",
       "NOX        0\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        0\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "LSTAT      0\n",
       "MEDV       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df.loc[:,df.columns!='MEDV']\n",
    "y = df.loc[:,df.columns=='MEDV']\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "x_train =mms.fit_transform(x_train)\n",
    "x_test =mms.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               1792      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_output (Dense)         (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 10,113\n",
      "Trainable params: 10,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(128,input_shape = (13,),activation = 'relu',name='dense_1'))\n",
    "model.add(Dense(64,activation = 'relu',name = 'dense_2'))\n",
    "model.add(Dense(1,activation='linear',name='dense_output'))\n",
    "\n",
    "model.compile(optimizer = 'adam',loss='mse',metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 336 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "336/336 [==============================] - 0s 850us/step - loss: 561.2633 - mae: 21.9167 - val_loss: 520.2896 - val_mae: 20.8477\n",
      "Epoch 2/100\n",
      "336/336 [==============================] - 0s 46us/step - loss: 517.6850 - mae: 20.8601 - val_loss: 467.3254 - val_mae: 19.4643\n",
      "Epoch 3/100\n",
      "336/336 [==============================] - 0s 48us/step - loss: 450.3872 - mae: 19.1428 - val_loss: 387.7397 - val_mae: 17.1472\n",
      "Epoch 4/100\n",
      "336/336 [==============================] - 0s 46us/step - loss: 353.1413 - mae: 16.3150 - val_loss: 279.7209 - val_mae: 13.2624\n",
      "Epoch 5/100\n",
      "336/336 [==============================] - 0s 41us/step - loss: 230.9467 - mae: 12.2540 - val_loss: 175.7267 - val_mae: 9.9846\n",
      "Epoch 6/100\n",
      "336/336 [==============================] - 0s 36us/step - loss: 136.6346 - mae: 8.8405 - val_loss: 140.6213 - val_mae: 9.9034\n",
      "Epoch 7/100\n",
      "336/336 [==============================] - 0s 40us/step - loss: 112.0229 - mae: 8.1799 - val_loss: 135.0391 - val_mae: 9.5706\n",
      "Epoch 8/100\n",
      "336/336 [==============================] - 0s 39us/step - loss: 100.0028 - mae: 7.6163 - val_loss: 110.8206 - val_mae: 8.6924\n",
      "Epoch 9/100\n",
      "336/336 [==============================] - 0s 35us/step - loss: 86.0326 - mae: 6.8469 - val_loss: 94.5229 - val_mae: 7.9732\n",
      "Epoch 10/100\n",
      "336/336 [==============================] - 0s 30us/step - loss: 76.6991 - mae: 6.3311 - val_loss: 82.3505 - val_mae: 7.4310\n",
      "Epoch 11/100\n",
      "336/336 [==============================] - 0s 38us/step - loss: 69.1437 - mae: 5.9873 - val_loss: 72.2516 - val_mae: 7.0161\n",
      "Epoch 12/100\n",
      "336/336 [==============================] - 0s 37us/step - loss: 63.4542 - mae: 5.7285 - val_loss: 62.6326 - val_mae: 6.5164\n",
      "Epoch 13/100\n",
      "336/336 [==============================] - 0s 38us/step - loss: 58.8633 - mae: 5.3994 - val_loss: 55.0623 - val_mae: 6.0549\n",
      "Epoch 14/100\n",
      "336/336 [==============================] - 0s 62us/step - loss: 55.5085 - mae: 5.2131 - val_loss: 49.9674 - val_mae: 5.7913\n",
      "Epoch 15/100\n",
      "336/336 [==============================] - 0s 39us/step - loss: 53.1792 - mae: 5.0824 - val_loss: 44.8697 - val_mae: 5.3995\n",
      "Epoch 16/100\n",
      "336/336 [==============================] - 0s 33us/step - loss: 51.3297 - mae: 4.9690 - val_loss: 41.4347 - val_mae: 5.1948\n",
      "Epoch 17/100\n",
      "336/336 [==============================] - 0s 30us/step - loss: 49.6656 - mae: 4.8716 - val_loss: 38.2010 - val_mae: 4.9013\n",
      "Epoch 18/100\n",
      "336/336 [==============================] - 0s 36us/step - loss: 48.3914 - mae: 4.7983 - val_loss: 36.2871 - val_mae: 4.7788\n",
      "Epoch 19/100\n",
      "336/336 [==============================] - 0s 40us/step - loss: 47.0819 - mae: 4.6918 - val_loss: 34.4807 - val_mae: 4.5975\n",
      "Epoch 20/100\n",
      "336/336 [==============================] - 0s 36us/step - loss: 45.5839 - mae: 4.6582 - val_loss: 34.4134 - val_mae: 4.7266\n",
      "Epoch 21/100\n",
      "336/336 [==============================] - 0s 30us/step - loss: 44.6574 - mae: 4.7037 - val_loss: 32.6076 - val_mae: 4.5287\n",
      "Epoch 22/100\n",
      "336/336 [==============================] - 0s 29us/step - loss: 43.0457 - mae: 4.4619 - val_loss: 30.5885 - val_mae: 4.2887\n",
      "Epoch 23/100\n",
      "336/336 [==============================] - 0s 42us/step - loss: 42.0077 - mae: 4.4152 - val_loss: 29.7669 - val_mae: 4.3112\n",
      "Epoch 24/100\n",
      "336/336 [==============================] - 0s 39us/step - loss: 40.6896 - mae: 4.3248 - val_loss: 28.6560 - val_mae: 4.2067\n",
      "Epoch 25/100\n",
      "336/336 [==============================] - 0s 35us/step - loss: 39.2635 - mae: 4.3106 - val_loss: 28.1793 - val_mae: 4.2539\n",
      "Epoch 26/100\n",
      "336/336 [==============================] - 0s 28us/step - loss: 38.0489 - mae: 4.2354 - val_loss: 26.5198 - val_mae: 4.0486\n",
      "Epoch 27/100\n",
      "336/336 [==============================] - 0s 42us/step - loss: 36.8493 - mae: 4.1646 - val_loss: 25.5357 - val_mae: 4.0068\n",
      "Epoch 28/100\n",
      "336/336 [==============================] - 0s 39us/step - loss: 35.6993 - mae: 4.0706 - val_loss: 23.7283 - val_mae: 3.7714\n",
      "Epoch 29/100\n",
      "336/336 [==============================] - 0s 39us/step - loss: 35.0253 - mae: 4.0861 - val_loss: 23.3142 - val_mae: 3.7940\n",
      "Epoch 30/100\n",
      "336/336 [==============================] - 0s 33us/step - loss: 33.5023 - mae: 3.9056 - val_loss: 21.5799 - val_mae: 3.5749\n",
      "Epoch 31/100\n",
      "336/336 [==============================] - 0s 31us/step - loss: 32.1973 - mae: 3.8358 - val_loss: 21.9841 - val_mae: 3.6897\n",
      "Epoch 32/100\n",
      "336/336 [==============================] - 0s 38us/step - loss: 31.4219 - mae: 3.8601 - val_loss: 20.8114 - val_mae: 3.5617\n",
      "Epoch 33/100\n",
      "336/336 [==============================] - 0s 47us/step - loss: 30.3821 - mae: 3.7438 - val_loss: 19.4826 - val_mae: 3.3888\n",
      "Epoch 34/100\n",
      "336/336 [==============================] - 0s 39us/step - loss: 29.7180 - mae: 3.6050 - val_loss: 17.7508 - val_mae: 3.1757\n",
      "Epoch 35/100\n",
      "336/336 [==============================] - 0s 39us/step - loss: 28.9031 - mae: 3.6592 - val_loss: 17.8033 - val_mae: 3.2338\n",
      "Epoch 36/100\n",
      "336/336 [==============================] - 0s 36us/step - loss: 28.0624 - mae: 3.5608 - val_loss: 17.4441 - val_mae: 3.1372\n",
      "Epoch 37/100\n",
      "336/336 [==============================] - 0s 33us/step - loss: 27.2310 - mae: 3.5434 - val_loss: 17.3197 - val_mae: 3.1427\n",
      "Epoch 38/100\n",
      "336/336 [==============================] - 0s 33us/step - loss: 26.6142 - mae: 3.4880 - val_loss: 15.5800 - val_mae: 2.8950\n",
      "Epoch 39/100\n",
      "336/336 [==============================] - 0s 39us/step - loss: 26.0678 - mae: 3.4160 - val_loss: 15.6522 - val_mae: 2.9504\n",
      "Epoch 40/100\n",
      "336/336 [==============================] - 0s 36us/step - loss: 25.5909 - mae: 3.4509 - val_loss: 15.0553 - val_mae: 2.8337\n",
      "Epoch 41/100\n",
      "336/336 [==============================] - 0s 36us/step - loss: 24.9716 - mae: 3.3264 - val_loss: 14.3829 - val_mae: 2.7855\n",
      "Epoch 42/100\n",
      "336/336 [==============================] - 0s 36us/step - loss: 24.4544 - mae: 3.3306 - val_loss: 14.7413 - val_mae: 2.8507\n",
      "Epoch 43/100\n",
      "336/336 [==============================] - 0s 33us/step - loss: 24.1312 - mae: 3.2886 - val_loss: 13.5392 - val_mae: 2.6889\n",
      "Epoch 44/100\n",
      "336/336 [==============================] - 0s 42us/step - loss: 23.7036 - mae: 3.2540 - val_loss: 14.5068 - val_mae: 2.8261\n",
      "Epoch 45/100\n",
      "336/336 [==============================] - 0s 41us/step - loss: 23.4225 - mae: 3.3029 - val_loss: 13.7643 - val_mae: 2.7289\n",
      "Epoch 46/100\n",
      "336/336 [==============================] - 0s 33us/step - loss: 23.0836 - mae: 3.1953 - val_loss: 13.2876 - val_mae: 2.6584\n",
      "Epoch 47/100\n",
      "336/336 [==============================] - 0s 39us/step - loss: 22.9671 - mae: 3.1943 - val_loss: 13.0457 - val_mae: 2.7221\n",
      "Epoch 48/100\n",
      "336/336 [==============================] - 0s 36us/step - loss: 22.5683 - mae: 3.1528 - val_loss: 11.8995 - val_mae: 2.5679\n",
      "Epoch 49/100\n",
      "336/336 [==============================] - 0s 36us/step - loss: 22.4664 - mae: 3.2136 - val_loss: 12.0271 - val_mae: 2.6563\n",
      "Epoch 50/100\n",
      "336/336 [==============================] - 0s 42us/step - loss: 22.5645 - mae: 3.1372 - val_loss: 10.5808 - val_mae: 2.3789\n",
      "Epoch 51/100\n",
      "336/336 [==============================] - 0s 44us/step - loss: 21.9429 - mae: 3.1965 - val_loss: 12.4959 - val_mae: 2.7546\n",
      "Epoch 52/100\n",
      "336/336 [==============================] - 0s 42us/step - loss: 21.7183 - mae: 3.1846 - val_loss: 11.3213 - val_mae: 2.5385\n",
      "Epoch 53/100\n",
      "336/336 [==============================] - 0s 33us/step - loss: 21.6098 - mae: 3.0658 - val_loss: 10.9541 - val_mae: 2.4805\n",
      "Epoch 54/100\n",
      "336/336 [==============================] - 0s 36us/step - loss: 21.5564 - mae: 3.1213 - val_loss: 10.7824 - val_mae: 2.4774\n",
      "Epoch 55/100\n",
      "336/336 [==============================] - 0s 39us/step - loss: 21.0719 - mae: 3.0914 - val_loss: 11.3015 - val_mae: 2.6008\n",
      "Epoch 56/100\n",
      "336/336 [==============================] - 0s 42us/step - loss: 21.0374 - mae: 3.0652 - val_loss: 11.0052 - val_mae: 2.5356\n",
      "Epoch 57/100\n",
      "336/336 [==============================] - 0s 42us/step - loss: 20.8558 - mae: 3.0848 - val_loss: 10.9247 - val_mae: 2.5216\n",
      "Epoch 58/100\n",
      "336/336 [==============================] - ETA: 0s - loss: 15.4025 - mae: 3.05 - 0s 30us/step - loss: 20.7429 - mae: 3.0302 - val_loss: 10.6572 - val_mae: 2.4797\n",
      "Epoch 59/100\n",
      "336/336 [==============================] - 0s 36us/step - loss: 20.4752 - mae: 3.0147 - val_loss: 10.8044 - val_mae: 2.5354\n",
      "Epoch 60/100\n",
      "336/336 [==============================] - 0s 38us/step - loss: 20.4421 - mae: 3.0143 - val_loss: 10.1191 - val_mae: 2.4700\n",
      "Epoch 61/100\n",
      "336/336 [==============================] - 0s 37us/step - loss: 20.2297 - mae: 3.0090 - val_loss: 11.0800 - val_mae: 2.5640\n",
      "Epoch 62/100\n",
      "336/336 [==============================] - 0s 39us/step - loss: 20.0255 - mae: 3.0096 - val_loss: 10.8849 - val_mae: 2.5669\n",
      "Epoch 63/100\n",
      "336/336 [==============================] - 0s 33us/step - loss: 19.9858 - mae: 3.0122 - val_loss: 10.3673 - val_mae: 2.4813\n",
      "Epoch 64/100\n",
      "336/336 [==============================] - 0s 33us/step - loss: 19.7379 - mae: 2.9628 - val_loss: 9.9649 - val_mae: 2.4561\n",
      "Epoch 65/100\n",
      "336/336 [==============================] - 0s 33us/step - loss: 19.7264 - mae: 3.0051 - val_loss: 10.4046 - val_mae: 2.5069\n",
      "Epoch 66/100\n",
      "336/336 [==============================] - 0s 39us/step - loss: 19.5841 - mae: 2.9267 - val_loss: 9.5241 - val_mae: 2.3854\n",
      "Epoch 67/100\n",
      "336/336 [==============================] - ETA: 0s - loss: 13.3700 - mae: 2.54 - 0s 34us/step - loss: 19.4566 - mae: 2.9931 - val_loss: 10.0383 - val_mae: 2.5052\n",
      "Epoch 68/100\n",
      "336/336 [==============================] - 0s 31us/step - loss: 19.0672 - mae: 2.9175 - val_loss: 9.0559 - val_mae: 2.2698\n",
      "Epoch 69/100\n",
      "336/336 [==============================] - 0s 34us/step - loss: 19.4425 - mae: 2.8857 - val_loss: 9.4412 - val_mae: 2.4275\n",
      "Epoch 70/100\n",
      "336/336 [==============================] - 0s 38us/step - loss: 19.6404 - mae: 3.0534 - val_loss: 9.0382 - val_mae: 2.3371\n",
      "Epoch 71/100\n",
      "336/336 [==============================] - 0s 37us/step - loss: 19.2615 - mae: 2.8596 - val_loss: 8.9571 - val_mae: 2.3299\n",
      "Epoch 72/100\n",
      "336/336 [==============================] - 0s 31us/step - loss: 19.1503 - mae: 2.9724 - val_loss: 9.4825 - val_mae: 2.4164\n",
      "Epoch 73/100\n",
      "336/336 [==============================] - 0s 30us/step - loss: 18.6671 - mae: 2.8039 - val_loss: 8.2207 - val_mae: 2.2112\n",
      "Epoch 74/100\n",
      "336/336 [==============================] - 0s 29us/step - loss: 18.3779 - mae: 2.8744 - val_loss: 9.8772 - val_mae: 2.5199\n",
      "Epoch 75/100\n",
      "336/336 [==============================] - 0s 32us/step - loss: 18.1220 - mae: 2.8571 - val_loss: 8.5498 - val_mae: 2.2231\n",
      "Epoch 76/100\n",
      "336/336 [==============================] - 0s 30us/step - loss: 18.3644 - mae: 2.8228 - val_loss: 10.3998 - val_mae: 2.5810\n",
      "Epoch 77/100\n",
      "336/336 [==============================] - 0s 30us/step - loss: 18.0327 - mae: 2.8893 - val_loss: 9.1957 - val_mae: 2.3866\n",
      "Epoch 78/100\n",
      "336/336 [==============================] - 0s 30us/step - loss: 18.1789 - mae: 2.7981 - val_loss: 8.3303 - val_mae: 2.2876\n",
      "Epoch 79/100\n",
      "336/336 [==============================] - 0s 27us/step - loss: 17.6709 - mae: 2.8137 - val_loss: 9.4588 - val_mae: 2.4781\n",
      "Epoch 80/100\n",
      "336/336 [==============================] - 0s 32us/step - loss: 17.8260 - mae: 2.7849 - val_loss: 8.5189 - val_mae: 2.3066\n",
      "Epoch 81/100\n",
      "336/336 [==============================] - 0s 30us/step - loss: 17.6146 - mae: 2.8322 - val_loss: 8.3484 - val_mae: 2.2802\n",
      "Epoch 82/100\n",
      "336/336 [==============================] - 0s 27us/step - loss: 17.7453 - mae: 2.7548 - val_loss: 7.9244 - val_mae: 2.2288\n",
      "Epoch 83/100\n",
      "336/336 [==============================] - 0s 30us/step - loss: 17.3496 - mae: 2.8143 - val_loss: 9.0612 - val_mae: 2.4284\n",
      "Epoch 84/100\n",
      "336/336 [==============================] - 0s 30us/step - loss: 17.2198 - mae: 2.7374 - val_loss: 8.1290 - val_mae: 2.2605\n",
      "Epoch 85/100\n",
      "336/336 [==============================] - 0s 24us/step - loss: 17.0625 - mae: 2.7558 - val_loss: 8.0646 - val_mae: 2.2803\n",
      "Epoch 86/100\n",
      "336/336 [==============================] - 0s 33us/step - loss: 16.8393 - mae: 2.7092 - val_loss: 8.1186 - val_mae: 2.2738\n",
      "Epoch 87/100\n",
      "336/336 [==============================] - 0s 29us/step - loss: 16.8657 - mae: 2.7103 - val_loss: 8.0746 - val_mae: 2.2698\n",
      "Epoch 88/100\n",
      "336/336 [==============================] - 0s 30us/step - loss: 16.7288 - mae: 2.7366 - val_loss: 8.0044 - val_mae: 2.2618\n",
      "Epoch 89/100\n",
      "336/336 [==============================] - 0s 33us/step - loss: 16.5775 - mae: 2.6985 - val_loss: 8.0593 - val_mae: 2.2651\n",
      "Epoch 90/100\n",
      "336/336 [==============================] - ETA: 0s - loss: 9.9992 - mae: 2.248 - 0s 29us/step - loss: 16.3870 - mae: 2.6722 - val_loss: 8.0676 - val_mae: 2.2883\n",
      "Epoch 91/100\n",
      "336/336 [==============================] - 0s 28us/step - loss: 16.3443 - mae: 2.7104 - val_loss: 7.3491 - val_mae: 2.1345\n",
      "Epoch 92/100\n",
      "336/336 [==============================] - 0s 33us/step - loss: 16.4149 - mae: 2.6463 - val_loss: 7.2748 - val_mae: 2.1774\n",
      "Epoch 93/100\n",
      "336/336 [==============================] - 0s 26us/step - loss: 16.1009 - mae: 2.6488 - val_loss: 7.6511 - val_mae: 2.2396\n",
      "Epoch 94/100\n",
      "336/336 [==============================] - 0s 29us/step - loss: 15.9782 - mae: 2.6606 - val_loss: 7.8025 - val_mae: 2.2533\n",
      "Epoch 95/100\n",
      "336/336 [==============================] - 0s 30us/step - loss: 16.0402 - mae: 2.6459 - val_loss: 8.1379 - val_mae: 2.3295\n",
      "Epoch 96/100\n",
      "336/336 [==============================] - 0s 27us/step - loss: 15.8301 - mae: 2.6762 - val_loss: 6.8742 - val_mae: 2.0732\n",
      "Epoch 97/100\n",
      "336/336 [==============================] - 0s 31us/step - loss: 16.0480 - mae: 2.6564 - val_loss: 7.1342 - val_mae: 2.1276\n",
      "Epoch 98/100\n",
      "336/336 [==============================] - 0s 28us/step - loss: 16.5906 - mae: 2.6104 - val_loss: 7.7203 - val_mae: 2.2921\n",
      "Epoch 99/100\n",
      "336/336 [==============================] - 0s 27us/step - loss: 15.9094 - mae: 2.7642 - val_loss: 7.6457 - val_mae: 2.2392\n",
      "Epoch 100/100\n",
      "336/336 [==============================] - 0s 31us/step - loss: 15.7862 - mae: 2.6189 - val_loss: 8.1029 - val_mae: 2.3221\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,epochs=100,validation_split=0.05,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 0s 26us/step\n",
      "MSE :  10.61967588725843\n",
      "MAE :  2.553501605987549\n"
     ]
    }
   ],
   "source": [
    "mse,mae = model.evaluate(x_test,y_test)\n",
    "print('MSE : ',mse)\n",
    "print('MAE : ',mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = model.predict(x_test[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>28.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>28.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>33.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>14.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MEDV\n",
       "307  28.2\n",
       "343  23.9\n",
       "47   16.6\n",
       "67   22.0\n",
       "362  20.8\n",
       "..    ...\n",
       "467  19.1\n",
       "95   28.4\n",
       "122  20.5\n",
       "260  33.8\n",
       "23   14.5\n",
       "\n",
       "[152 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=[]\n",
    "for i in y1:\n",
    "    ps.append(list(i)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame({'actual':y_test['MEDV'],'predicted':ps})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>28.2</td>\n",
       "      <td>30.009384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>23.9</td>\n",
       "      <td>26.553017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>16.6</td>\n",
       "      <td>18.823812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>22.0</td>\n",
       "      <td>21.590239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>20.8</td>\n",
       "      <td>22.718721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>19.1</td>\n",
       "      <td>14.809460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>28.4</td>\n",
       "      <td>27.313490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>20.5</td>\n",
       "      <td>19.907228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>33.8</td>\n",
       "      <td>34.766129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>14.5</td>\n",
       "      <td>16.065664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual  predicted\n",
       "307    28.2  30.009384\n",
       "343    23.9  26.553017\n",
       "47     16.6  18.823812\n",
       "67     22.0  21.590239\n",
       "362    20.8  22.718721\n",
       "..      ...        ...\n",
       "467    19.1  14.809460\n",
       "95     28.4  27.313490\n",
       "122    20.5  19.907228\n",
       "260    33.8  34.766129\n",
       "23     14.5  16.065664\n",
       "\n",
       "[152 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
